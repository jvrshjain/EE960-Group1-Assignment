{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZfu8NgCjQMVQ4S5w0QLjO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvrshjain/EE960-Group1-Assignment/blob/main/Using_random_forest_regressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB16GOmfshqx",
        "outputId": "76865674-9018-41c1-9bf5-54a94133c15b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data points (weeks): 310\n",
            "Training Set Size (80%): 248 weeks, up to 2019-10-27\n",
            "Test Set Size (20%): 62 weeks, starting from 2019-11-03\n",
            "--------------------------------------------------\n",
            "## Model Performance Metrics:\n",
            "MAE: 1.1774\n",
            "MSE: 2.2845\n",
            "R2 Score: 0.7767\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_name = \"Temp_and_humidity_dataset.csv\"\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# Inspect the data\n",
        "# print(\"Data head:\")\n",
        "# print(df.head())\n",
        "# print(\"\\nData info:\")\n",
        "# df.info()\n",
        "\n",
        "# 1. Prepare Data: Convert DATETIME and set index\n",
        "df['DATETIME'] = pd.to_datetime(df['DATETIME'])\n",
        "df = df.set_index('DATETIME').sort_index()\n",
        "\n",
        "# 2. Weekly Aggregation\n",
        "# Resample to weekly mean\n",
        "df_weekly = df.resample('W').mean().dropna()\n",
        "\n",
        "# 3. Feature Engineering\n",
        "# A. Time-Based Features (Seasonality)\n",
        "df_weekly['Month'] = df_weekly.index.month\n",
        "# isocalendar().week ensures consistent week numbering across years\n",
        "df_weekly['Week_of_Year'] = df_weekly.index.isocalendar().week.astype(int)\n",
        "\n",
        "# B. Lagged Features (Time Dependence)\n",
        "# Lag 1 (Previous week) and Lag 4 (Four weeks prior/approx. a month prior)\n",
        "df_weekly['Temp_Lag_1'] = df_weekly['TEMPERATURE'].shift(1)\n",
        "df_weekly['Humidity_Lag_1'] = df_weekly['HUMIDITY'].shift(1)\n",
        "df_weekly['Temp_Lag_4'] = df_weekly['TEMPERATURE'].shift(4)\n",
        "\n",
        "# Drop rows with NaN values created by the shift operations (the first 4 weeks)\n",
        "df_final = df_weekly.dropna()\n",
        "\n",
        "# --- Model Preparation ---\n",
        "\n",
        "# Target is the current week's Average Temperature\n",
        "Y = df_final['TEMPERATURE']\n",
        "\n",
        "# Features (Time and Lagged features, excluding current week's data to simulate sensor failure backup)\n",
        "X = df_final[['Month', 'Week_of_Year', 'Temp_Lag_1', 'Humidity_Lag_1', 'Temp_Lag_4']]\n",
        "\n",
        "# 4. Chronological Train/Test Split (80:20)\n",
        "split_idx = int(len(X) * 0.8)\n",
        "\n",
        "# Chronological Split: Earlier 80% for training, later 20% for testing\n",
        "X_train = X.iloc[:split_idx]\n",
        "X_test = X.iloc[split_idx:]\n",
        "Y_train = Y.iloc[:split_idx]\n",
        "Y_test = Y.iloc[split_idx:]\n",
        "\n",
        "# Print split dates for context\n",
        "print(f\"Total data points (weeks): {len(df_final)}\")\n",
        "print(f\"Training Set Size (80%): {len(X_train)} weeks, up to {X_train.index.max().date()}\")\n",
        "print(f\"Test Set Size (20%): {len(X_test)} weeks, starting from {X_test.index.min().date()}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 5. Model Training (Random Forest Regressor)\n",
        "# Using n_estimators=100 and a fixed random_state for reproducibility\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# 6. Prediction and Evaluation\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "# Store results for the report\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'R2 Score'],\n",
        "    'Value': [mae, mse, r2]\n",
        "})\n",
        "\n",
        "print(\"## Model Performance Metrics:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n"
      ]
    }
  ]
}